{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id='top'></a>\n# Automated Question Answering System\n\nWe are going to work on Document Retrieval in [Stanford Question Answering Dataset](https://www.kaggle.com/datasets/stanfordu/stanford-question-answering-dataset). Let's see how algorithms handled the problems.\n\nCheck Testing Scores [SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/)\n\n![image](https://qa.fastforwardlabs.com/images/copied_from_nb/my_icons/QAworkflow.png)\n_Image from [Intro to Automated Question Answering](https://qa.fastforwardlabs.com/methods/background/2020/04/28/Intro-to-QA.html)._","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install wikipedia==1.4.0\n!pip install scikit-learn==1.0.2\n!pip install gensim==4.0.1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:19:56.515454Z","iopub.execute_input":"2023-09-26T17:19:56.515810Z","iopub.status.idle":"2023-09-26T17:20:34.558015Z","shell.execute_reply.started":"2023-09-26T17:19:56.515720Z","shell.execute_reply":"2023-09-26T17:20:34.556875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## What do we want to do?\n\nWe want to create a Document Retrieval, like a search tool, such as Wikipedia. Let's explore the `wikipedia` library, to see the retriever in action.","metadata":{}},{"cell_type":"code","source":"import wikipedia as wiki\n\nk = 5\nquestion = \"What are the tourist hotspots in Portugal?\"\n\nresults = wiki.search(question, results=k)\nprint('Question:', question)\nprint('Pages:  ', results)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:34.560334Z","iopub.execute_input":"2023-09-26T17:20:34.560613Z","iopub.status.idle":"2023-09-26T17:20:35.293061Z","shell.execute_reply.started":"2023-09-26T17:20:34.560579Z","shell.execute_reply":"2023-09-26T17:20:35.292256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discussion\n\nFor this question, Wikipedia's Document Retrieval returned the 5 most likely pages that contain the answer to the question.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"data\"></a>\n\n---\n# Data Exploration\n\nIn this section, we are going to load a `json` file into a `pandas.DataFrame`. At last, elaborate our list of documents.\n\n[Back to Top](#top)","metadata":{}},{"cell_type":"code","source":"import json\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:35.294380Z","iopub.execute_input":"2023-09-26T17:20:35.295189Z","iopub.status.idle":"2023-09-26T17:20:35.299421Z","shell.execute_reply.started":"2023-09-26T17:20:35.295132Z","shell.execute_reply":"2023-09-26T17:20:35.298544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# list the available data\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:20:35.302195Z","iopub.execute_input":"2023-09-26T17:20:35.302456Z","iopub.status.idle":"2023-09-26T17:20:35.326881Z","shell.execute_reply.started":"2023-09-26T17:20:35.302420Z","shell.execute_reply":"2023-09-26T17:20:35.326231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# based on: https://www.kaggle.com/code/sanjay11100/squad-stanford-q-a-json-to-pandas-dataframe\ndef squad_json_to_dataframe(file_path, record_path=['data','paragraphs','qas','answers']):\n    \"\"\"\n    input_file_path: path to the squad json file.\n    record_path: path to deepest level in json file default value is\n    ['data','paragraphs','qas','answers']\n    \"\"\"\n    file = json.loads(open(file_path).read())\n    # parsing different level's in the json file\n    js = pd.json_normalize(file, record_path)\n    m = pd.json_normalize(file, record_path[:-1])\n    r = pd.json_normalize(file,record_path[:-2])\n    # combining it into single dataframe\n    idx = np.repeat(r['context'].values, r.qas.str.len())\n    m['context'] = idx\n    data = m[['id','question','context','answers']].set_index('id').reset_index()\n    data['c_id'] = data['context'].factorize()[0]\n    return data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:20:35.328150Z","iopub.execute_input":"2023-09-26T17:20:35.328592Z","iopub.status.idle":"2023-09-26T17:20:35.336814Z","shell.execute_reply.started":"2023-09-26T17:20:35.328557Z","shell.execute_reply":"2023-09-26T17:20:35.336103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading the data\nfile_path = '/kaggle/input/stanford-question-answering-dataset/train-v1.1.json'\ndata = squad_json_to_dataframe(file_path)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:35.338201Z","iopub.execute_input":"2023-09-26T17:20:35.338651Z","iopub.status.idle":"2023-09-26T17:20:42.684884Z","shell.execute_reply.started":"2023-09-26T17:20:35.338615Z","shell.execute_reply":"2023-09-26T17:20:42.684107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# how many documents do we have?\ndata['c_id'].unique().size","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:42.686071Z","iopub.execute_input":"2023-09-26T17:20:42.686358Z","iopub.status.idle":"2023-09-26T17:20:42.695418Z","shell.execute_reply.started":"2023-09-26T17:20:42.686319Z","shell.execute_reply":"2023-09-26T17:20:42.694653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the Unique Documents\n\nLet's select the unique documents in our `data`. This will be the list of documents to search for the answers.","metadata":{}},{"cell_type":"code","source":"documents = data[['context', 'c_id']].drop_duplicates().reset_index(drop=True)\ndocuments","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:42.696885Z","iopub.execute_input":"2023-09-26T17:20:42.697166Z","iopub.status.idle":"2023-09-26T17:20:42.824837Z","shell.execute_reply.started":"2023-09-26T17:20:42.697128Z","shell.execute_reply":"2023-09-26T17:20:42.823941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"document\"></a>\n\n---\n# Document Retrieval\n\nIn this section, we are going to explore the techniques to retrieve documents. First, we are going to create our document `vectorizer`. We use this `vectorizer` to encode the documents and the questions into vectors. After, we can search for a question comparing with the document vectors. In the end, the algorithm will return the $k$ most similar document vectors to a question vector.\n","metadata":{}},{"cell_type":"markdown","source":"## TF-IDF\n\n\"In information retrieval, TF-IDF, short for term frequencyâ€“inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.\" ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import NearestNeighbors\n\n# defining the TF-IDF\ntfidf_configs = {\n    'lowercase': True,\n    'analyzer': 'word',\n    'stop_words': 'english',\n    'binary': True,\n    'max_df': 0.9,\n    'max_features': 10_000\n}\n# defining the number of documents to retrieve\nretriever_configs = {\n    'n_neighbors': 10,\n    'metric': 'cosine'\n}\n\n# defining our pipeline\nembedding = TfidfVectorizer(**tfidf_configs)\nretriever = NearestNeighbors(**retriever_configs)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:42.826483Z","iopub.execute_input":"2023-09-26T17:20:42.826759Z","iopub.status.idle":"2023-09-26T17:20:43.581856Z","shell.execute_reply.started":"2023-09-26T17:20:42.826722Z","shell.execute_reply":"2023-09-26T17:20:43.581078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's train the model to retrieve the document id 'c_id'\nX = embedding.fit_transform(documents['context'])\nretriever.fit(X, documents['c_id'])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:43.585013Z","iopub.execute_input":"2023-09-26T17:20:43.585662Z","iopub.status.idle":"2023-09-26T17:20:46.078533Z","shell.execute_reply.started":"2023-09-26T17:20:43.585620Z","shell.execute_reply":"2023-09-26T17:20:46.077609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's test the vectorizer, what information our model is using to extract the vector?","metadata":{}},{"cell_type":"code","source":"def transform_text(vectorizer, text):\n    '''\n    Print the text and the vector[TF-IDF]\n    vectorizer: sklearn.vectorizer\n    text: str\n    '''\n    print('Text:', text)\n    vector = vectorizer.transform([text])\n    vector = vectorizer.inverse_transform(vector)\n    print('Vect:', vector)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:20:46.079870Z","iopub.execute_input":"2023-09-26T17:20:46.080795Z","iopub.status.idle":"2023-09-26T17:20:46.086776Z","shell.execute_reply.started":"2023-09-26T17:20:46.080753Z","shell.execute_reply":"2023-09-26T17:20:46.086046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vectorize the question\ntransform_text(embedding, question)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:46.088462Z","iopub.execute_input":"2023-09-26T17:20:46.089042Z","iopub.status.idle":"2023-09-26T17:20:46.111021Z","shell.execute_reply.started":"2023-09-26T17:20:46.088991Z","shell.execute_reply":"2023-09-26T17:20:46.110290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What is the most similar document to this question?","metadata":{}},{"cell_type":"code","source":"# predict the most similar document\nX = embedding.transform([question])\nc_id = retriever.kneighbors(X, return_distance=False)[0][0]\nselected = documents.iloc[c_id]['context']\n\n# vectorize the document\ntransform_text(embedding, selected)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:46.112208Z","iopub.execute_input":"2023-09-26T17:20:46.112463Z","iopub.status.idle":"2023-09-26T17:20:46.150821Z","shell.execute_reply.started":"2023-09-26T17:20:46.112425Z","shell.execute_reply":"2023-09-26T17:20:46.149931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"%%time\n# predict one document for each question\nX = embedding.transform(data['question'])\ny_test = data['c_id']\ny_pred = retriever.kneighbors(X, return_distance=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:20:46.152198Z","iopub.execute_input":"2023-09-26T17:20:46.152538Z","iopub.status.idle":"2023-09-26T17:21:24.556513Z","shell.execute_reply.started":"2023-09-26T17:20:46.152491Z","shell.execute_reply":"2023-09-26T17:21:24.555698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top documents predicted for each question\ny_pred","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:21:24.557873Z","iopub.execute_input":"2023-09-26T17:21:24.558780Z","iopub.status.idle":"2023-09-26T17:21:24.566201Z","shell.execute_reply.started":"2023-09-26T17:21:24.558730Z","shell.execute_reply":"2023-09-26T17:21:24.565240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def top_accuracy(y_true, y_pred) -> float:\n    right, count = 0, 0\n    for i, y_t in enumerate(y_true):\n        count += 1\n        if y_t in y_pred[i]:\n            right += 1\n    return right / count if count > 0 else 0","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:21:24.567542Z","iopub.execute_input":"2023-09-26T17:21:24.568459Z","iopub.status.idle":"2023-09-26T17:21:24.577916Z","shell.execute_reply.started":"2023-09-26T17:21:24.568417Z","shell.execute_reply":"2023-09-26T17:21:24.577201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = top_accuracy(y_test, y_pred)\nprint('Accuracy:', f'{acc:.4f}')\nprint('Quantity:', int(acc*len(y_pred)), 'from', len(y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:21:24.579378Z","iopub.execute_input":"2023-09-26T17:21:24.579700Z","iopub.status.idle":"2023-09-26T17:21:24.998594Z","shell.execute_reply.started":"2023-09-26T17:21:24.579666Z","shell.execute_reply":"2023-09-26T17:21:24.997127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discussion\n\n1. This is a difficult problem, because we have multiples documents (in this notebook, ~19k documents) and the answer can be in one or more documents. Thus, the retriever usually returns $k$ documents, because it is not complete/fair return only one document.\n2. We reach a high accuracy with top-10 (71.48%); in top-1 a low accuray (43.22%) becase we have a lot of documents, and some are pretty similar. Actually, this top-1 and top-10 are very good accuracy for this problem.\n3. TF-IDF has some problems: (1) this algorithm is only able to compute similarity between questions and documents that present the same words, so it can not capture synonyms; and (2) cannot understand the question context or the meaning of the words.","metadata":{}},{"cell_type":"markdown","source":"## Word2Vec / Embedding\n\n\"Word2vec is a technique for natural language processing published in 2013. The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence.\"","metadata":{}},{"cell_type":"code","source":"from gensim.parsing.preprocessing import preprocess_string\n\n# create a corpus of tokens\ncorpus = documents['context'].tolist()\ncorpus = [preprocess_string(t) for t in corpus]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:21:25.000148Z","iopub.execute_input":"2023-09-26T17:21:25.000419Z","iopub.status.idle":"2023-09-26T17:21:46.607771Z","shell.execute_reply.started":"2023-09-26T17:21:25.000383Z","shell.execute_reply":"2023-09-26T17:21:46.606932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import Word2Vec\nimport gensim.downloader\n\n# you can download a pretrained Word2Vec\n# - or you can train your own model\n\n# download a model\n# 'glove-wiki-gigaword-300' (376.1 MB)\n# 'word2vec-ruscorpora-300' (198.8 MB)\n# 'word2vec-google-news-300' (1.6 GB)\n# vectorizer = gensim.downloader.load('word2vec-ruscorpora-300')\n\n# train your own model\nvectorizer = Word2Vec(sentences=corpus, vector_size=300, window=5, min_count=1, workers=4).wv","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-26T17:21:46.609513Z","iopub.execute_input":"2023-09-26T17:21:46.609784Z","iopub.status.idle":"2023-09-26T17:22:04.656737Z","shell.execute_reply.started":"2023-09-26T17:21:46.609746Z","shell.execute_reply":"2023-09-26T17:22:04.655926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# similar words to 'tourist'\nvectorizer.most_similar('tourist', topn=5)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:22:04.657972Z","iopub.execute_input":"2023-09-26T17:22:04.658266Z","iopub.status.idle":"2023-09-26T17:22:04.704226Z","shell.execute_reply.started":"2023-09-26T17:22:04.658228Z","shell.execute_reply":"2023-09-26T17:22:04.703471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_text2(vectorizer, text, verbose=False):\n    '''\n    Transform the text in a vector[Word2Vec]\n    vectorizer: sklearn.vectorizer\n    text: str\n    '''\n    tokens = preprocess_string(text)\n    words = [vectorizer[w] for w in tokens if w in vectorizer]\n    if verbose:\n        print('Text:', text)\n        print('Vector:', [w for w in tokens if w in vectorizer])\n    elif len(words):\n        return np.mean(words, axis=0)\n    else:\n        return np.zeros((300), dtype=np.float32)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:22:04.705427Z","iopub.execute_input":"2023-09-26T17:22:04.706208Z","iopub.status.idle":"2023-09-26T17:22:04.715105Z","shell.execute_reply.started":"2023-09-26T17:22:04.706152Z","shell.execute_reply":"2023-09-26T17:22:04.714025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# just testing our Word2Vec\ntransform_text2(vectorizer, question, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:22:04.716329Z","iopub.execute_input":"2023-09-26T17:22:04.717092Z","iopub.status.idle":"2023-09-26T17:22:04.729640Z","shell.execute_reply.started":"2023-09-26T17:22:04.717051Z","shell.execute_reply":"2023-09-26T17:22:04.728627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's train the model to retrieve the document id 'c_id'\nretriever2 = NearestNeighbors(**retriever_configs)\n\n# vectorizer the documents, fit the retriever\nX = documents['context'].apply(lambda x: transform_text2(vectorizer, x)).tolist()\nretriever2.fit(X, documents['c_id'])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:22:04.730668Z","iopub.execute_input":"2023-09-26T17:22:04.731617Z","iopub.status.idle":"2023-09-26T17:22:33.393089Z","shell.execute_reply.started":"2023-09-26T17:22:04.731575Z","shell.execute_reply":"2023-09-26T17:22:33.392216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"%%time\n# vectorizer the questions\nX = data['question'].apply(lambda x: transform_text2(vectorizer, x)).tolist()\n\n# predict one document for each question\ny_test = data['c_id']\ny_pred = retriever2.kneighbors(X, return_distance=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:22:33.394735Z","iopub.execute_input":"2023-09-26T17:22:33.395004Z","iopub.status.idle":"2023-09-26T17:23:20.556597Z","shell.execute_reply.started":"2023-09-26T17:22:33.394969Z","shell.execute_reply":"2023-09-26T17:23:20.555825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top documents predicted for each question\ny_pred","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:23:20.560813Z","iopub.execute_input":"2023-09-26T17:23:20.562864Z","iopub.status.idle":"2023-09-26T17:23:20.573186Z","shell.execute_reply.started":"2023-09-26T17:23:20.562822Z","shell.execute_reply":"2023-09-26T17:23:20.572374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = top_accuracy(y_test, y_pred)\nprint('Accuracy:', f'{acc:.4f}')\nprint('Quantity:', int(acc*len(y_pred)), 'from', len(y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:23:20.577681Z","iopub.execute_input":"2023-09-26T17:23:20.578799Z","iopub.status.idle":"2023-09-26T17:23:21.239629Z","shell.execute_reply.started":"2023-09-26T17:23:20.578760Z","shell.execute_reply":"2023-09-26T17:23:21.238893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discussion\n\n1. We did not reach a good accuracy (12.15%) in top-10; and a really low accuray (3.07%) in top-1. Thus, the TF-IDF was better.\n2. Maybe, the `vectorizer` did not receive enough data to be trained. Thus, I suggest use pretrained models, like `'word2vec-google-news-300'`.\n3. Another problem: I simply compute the average of the words to compose the document/question embedding; we do have other pooling strategies to work with sentences. Or, we can try more robust embedding techniques, such as BERT, MT5, DPR, etc.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"discussion\"></a>\n\n---\n# Conclusion\n\n1. As mentioned, this problem is really complex, due to the number of documents.\n2. TF-IDF reached a great top-10 accuracy (71.48%) for this dataset, and it can increases returning more documents.\n3. We also have other algorithms to work with Document Retriveal, such as [BM25](https://pypi.org/project/rank-bm25/) and [DPR](https://aclanthology.org/2020.emnlp-main.550/).\n\n## Reference\n\n1. [Intro to Automated Question Answering](https://qa.fastforwardlabs.com/methods/background/2020/04/28/Intro-to-QA.html)\n2. [Building a QA System with BERT on Wikipedia](https://qa.fastforwardlabs.com/pytorch/hugging%20face/wikipedia/bert/transformers/2020/05/19/Getting_Started_with_QA.html)\n3. [Evaluating QA: Metrics, Predictions, and the Null Response](https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html)\n4. [Dense Passage Retrieval for Open-Domain Question Answering](https://aclanthology.org/2020.emnlp-main.550/)","metadata":{}}]}